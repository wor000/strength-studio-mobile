import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'
import OpenAI from 'https://esm.sh/openai@4.28.0'
import { generatePrompt } from './prompt-generator.ts'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  try {
    // Verificar variÃ¡veis de ambiente (reduzido logs)
    const openaiKey = Deno.env.get('OPENAI_API_KEY')
    
    if (!openaiKey) {
      throw new Error('OPENAI_API_KEY environment variable is not set')
    }
    
    const { message, conversationHistory = [], userProfile } = await req.json()

    const openai = new OpenAI({
      apiKey: openaiKey,
    })

    // LÃ“GICA ULTRA-SIMPLIFICADA
    let workoutGenerated = false
    let finalAiResponse = ''

    // Pegar a Ãºltima mensagem da IA para verificar se termina com a pergunta
    const lastAIMessage = conversationHistory
      .filter(msg => msg.role === 'assistant')
      .pop()

    const userSaidYes = message.toLowerCase().trim() === 'sim'
    const lastResponseHasQuestion = lastAIMessage?.content?.includes('ðŸ”¥ QUER QUE EU ADICIONE AO APP?')

    if (userSaidYes && lastResponseHasQuestion) {
      // UsuÃ¡rio confirmou - resposta curta e otimizada
      workoutGenerated = true
      finalAiResponse = "âœ… Treino adicionado! VÃ¡ para 'Treinos Gerados' para aceitar. ðŸ’ª"
    } else {
      // Conversa normal - IA processa com limite de tokens reduzido
      const prompt = generatePrompt(message, conversationHistory, userProfile)
      
      const response = await openai.chat.completions.create({
        model: 'gpt-4o-mini', // Modelo mais eficiente
        messages: [
          {
            role: 'system',
            content: prompt
          },
          // Limitar histÃ³rico para reduzir payload
          ...conversationHistory.slice(-6), // Apenas Ãºltimas 6 mensagens
          {
            role: 'user',
            content: message
          }
        ],
        temperature: 0.1,
        max_tokens: 1000, // Reduzido de 2000 para 1000
        stream: false
      })

      finalAiResponse = response.choices[0].message.content || 'Erro na resposta.'
    }

    // Resposta mÃ­nima para reduzir egress
    return new Response(
      JSON.stringify({
        response: finalAiResponse,
        workoutGenerated
      }),
      {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      },
    )

  } catch (error) {
    // Log mÃ­nimo em produÃ§Ã£o
    console.error('AI Error:', error.message)
    
    return new Response(
      JSON.stringify({ 
        error: 'Erro interno',
        response: 'Erro temporÃ¡rio. Tente novamente.',
        workoutGenerated: false
      }),
      {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      },
    )
  }
})
